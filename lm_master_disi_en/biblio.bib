% book
% Required fields: author or editor, title, publisher, year. 
% Optional fields: volume or number, series, address, edition, month, note.
@book{coulouris,
  author = {Coulouris  G.  F.,  Dollimore J. e  Kindberg T},
  title = {Distributed Systems: concepts and Design},
  publisher = {Addison-Wesley},
  year = {1994},
  edition = "second edition"

}

% article
% Required fields: author, title, journal, year. 
% Optional fields: volume, number, pages, month, note.
@article{donoho,
  author = {Donoho D. L.},
  title = {Compressed Sensing},
  journal = {IEEE Trans. Inf. Theory},
  volume = {52},
  number = {4},
  pages = {1289-1306},
  year = {2006}
}

% conference
% same as inproceedings
% Required fields: author, title, booktitle, year. 
% Optional fields: editor, volume or number, series, pages, address, month, organization, publisher, note
@conference{dalal,
  author = {Dalal N., Triggs B.},
  title = {Histograms of Oriented Gradients for Human Detection},
  booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  address = {San Diego, USA},
  year = {2005},
  month = {20-26 June},
  pages = {886-893}
}

% website
% as misc
% Required fields: none. 
% Optional fields: author, title, howpublished, month, year, note.
@misc{ictbusiness,
  title = {ICT business},
  howpublished = {http://www.ictbusiness.it/},
  note = {ultimo accesso 15/06/2015}
}
% website
% as misc
% Required fields: none. 
% Optional fields: author, title, howpublished, month, year, note.
@misc{llm-autonomous-agents,
  title = {LLM Powered Autonomous Agents},
  howpublished = {https://lilianweng.github.io/posts/2023-06-23-agent/?ref=emergentmind}
}

@misc{llm-prompt-engineering,
  title = {Prompt Engineering},
  howpublished = {https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/}
}
@misc{copilot,
      title={CoPilot}, 
      author={Github},
    howpublished = {https://github.com/features/copilot}
}
@misc{bai2022constitutional,
      title={Constitutional AI: Harmlessness from AI Feedback}, 
      author={Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan},
      year={2022},
      eprint={2212.08073},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{park2023generative,
      title={Generative Agents: Interactive Simulacra of Human Behavior}, 
      author={Joon Sung Park and Joseph C. O'Brien and Carrie J. Cai and Meredith Ringel Morris and Percy Liang and Michael S. Bernstein},
      year={2023},
      eprint={2304.03442},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}

@misc{hsieh2023distilling,
      title={Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes}, 
      author={Cheng-Yu Hsieh and Chun-Liang Li and Chih-Kuan Yeh and Hootan Nakhost and Yasuhisa Fujii and Alexander Ratner and Ranjay Krishna and Chen-Yu Lee and Tomas Pfister},
      year={2023},
      eprint={2305.02301},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{boiko2023emergent,
      title={Emergent autonomous scientific research capabilities of large language models}, 
      author={Daniil A. Boiko and Robert MacKnight and Gabe Gomes},
      year={2023},
      eprint={2304.05332},
      archivePrefix={arXiv},
      primaryClass={physics.chem-ph}
}
@misc{bubeck2023sparks,
      title={Sparks of Artificial General Intelligence: Early experiments with GPT-4}, 
      author={Sébastien Bubeck and Varun Chandrasekaran and Ronen Eldan and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
      year={2023},
      eprint={2303.12712},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@article{chen2021evaluating,
  title={Evaluating Large Language Models Trained on Code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Ponde de Oliveira Pinto, Henrique and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv e-prints},
  pages={arXiv--2107},
  year={2021}
}
@misc{chatgpt-see,
    title = {ChatGPT can now see, hear, and speak},
    author = {OpenAI},
    howpublished = {https://openai.com/blog/chatgpt-can-now-see-hear-and-speak}
}
@misc{chatgpt,
    title = {ChatGPT},
    author = {OpenAI},
    howpublished = {https://openai.com/chatgpt}
}
@article{touvronllama,
  title={LLaMA: Open and Efficient Foundation Language Models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothee and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others}
}

@misc{bard,
    title={Google Bard},
    author = {Google},
    howpublished = {https://ai.google/static/documents/google-about-bard.pdf}
    
}

@misc{ai-plugins,
    title={Microsoft AI plugins},
    author = {Microsoft},
    howpublished = {https://blogs.microsoft.com/blog/2023/05/23/microsoft-build-brings-ai-tools-to-the-forefront-for-developers/}
    
}
@misc{personal-narrative-wikipedia,
    title={Personal Narrative},
    author={Wikipedia},
howpublished = {https://en.wikipedia.org/wiki/Personal_narrative#:~:text=Personal%20narrative%20(PN)%20is%20a,typical%20criteria%20of%20a%20narrative.}
}
@misc{personal-narrative-academic,
    title={Personal Narrative},
    author={Academic},
howpublished = {https://academic-accelerator.com/encyclopedia/personal-narrative}
}
@article{tammewarannotation,
  title={Annotation of Emotion Carriers in Personal Narratives},
  author={Tammewar, Aniruddha and Cervone, Alessandra and Messner, Eva-Maria and Riccardi, Giuseppe}
}

@article{mostafazadeh2016corpus,
  title={A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories},
  author={Mostafazadeh, Nasrin and Chambers, Nathanael and He, Xiaodong and Parikh, Devi and Batra, Dhruv and Vanderwende, Lucy and Kohli, Pushmeet and Allen, James}
}
@misc{elicitation-wikipedia,
    title={Elicitation techniques},
    author={Wikipedia},
howpublished = {https://en.wikipedia.org/wiki/Elicitation_technique}
}
@article{ee5361a4-99b9-3fb2-997e-da5e4c6cb553,
 ISSN = {0034527X},
 URL = {http://www.jstor.org/stable/40171631},
 abstract = {In this paper I describe two contrasting classroom contexts for eliciting personal narratives, Drawing from a larger study in which I followed one second language learner as he proceeded through 2nd and 3rd grade, my analysis is based on reading group interactions video-recorded weekly during the second semester of each year. Comparison of oral narrative elicitation across years reveals two very different participation contexts. In one context narrative elicitation occurred primarily in two-person dialogue with the teacher. In another context oral narrative emerged through multi-party dialogue after the official lesson had closed. These contrasting contexts thus facilitated qualitatively different forms of co-tellership and as a consequence different opportunities for oral narrative. I intend this analysis of narrative elicitation to draw attention to the margins of classroom activity and by doing so to take a step toward a discourse-based solution to what has been recognized as a discourse-based problem in schools: differential access to oral preparation for literacy.},
 author = {Betsy Rymes},
 journal = {Research in the Teaching of English},
 number = {3},
 pages = {380--407},
 publisher = {National Council of Teachers of English},
 title = {Eliciting Narratives: Drawing Attention to the Margins of Classroom Talk},
 urldate = {2023-10-02},
 volume = {37},
 year = {2003}
}
@inproceedings{mousavi-etal-2022-evaluation,
    title = "Evaluation of Response Generation Models: Shouldn{'}t It Be Shareable and Replicable?",
    author = "Mousavi, Seyed Mahed  and
      Roccabruna, Gabriel  and
      Lorandi, Michela  and
      Caldarella, Simone  and
      Riccardi, Giuseppe",
    booktitle = "Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.gem-1.12",
    doi = "10.18653/v1/2022.gem-1.12",
    pages = "136--147",
    abstract = "Human Evaluation (HE) of automatically generated responses is necessary for the advancement of human-machine dialogue research. Current automatic evaluation measures are poor surrogates, at best. There are no agreed-upon HE protocols and it is difficult to develop them. As a result, researchers either perform non-replicable, non-transparent and inconsistent procedures or, worse, limit themselves to automated metrics. We propose to standardize the human evaluation of response generation models by publicly sharing a detailed protocol. The proposal includes the task design, annotators recruitment, task execution, and annotation reporting. Such protocol and process can be used as-is, as-a-whole, in-part, or modified and extended by the research community. We validate the protocol by evaluating two conversationally fine-tuned state-of-the-art models (GPT-2 and T5) for the complex task of personalized response generation. We invite the community to use this protocol - or its future community amended versions - as a transparent, replicable, and comparable approach to HE of generated responses.",
}

@misc{bootstrap,
    title = {BootStrap},
    author = {BootStrap},
    howpublished = {https://getbootstrap.com}
}
@mic{material,
title = {Material Design},
author = {Google},
howpublished = {https://m3.material.io}

}
@misc{prolific,
title = {Prolific},
author= {Prolific},
howpublished = {https://www.prolific.co}
}
@misc{huggingface-leaderboard,
title = {HuggingFace Open-Source LLM Leaderboard},
author= {HuggingFace},
howpublished = {https://huggingface.co/spaces/HuggingFaceH4/open\_llm\_leaderboard}
}
@software{eleuther,
  author       = {Gao, Leo and
                  Tow, Jonathan and
                  Biderman, Stella and
                  Black, Sid and
                  DiPofi, Anthony and
                  Foster, Charles and
                  Golding, Laurence and
                  Hsu, Jeffrey and
                  McDonell, Kyle and
                  Muennighoff, Niklas and
                  Phang, Jason and
                  Reynolds, Laria and
                  Tang, Eric and
                  Thite, Anish and
                  Wang, Ben and
                  Wang, Kevin and
                  Zou, Andy},
  title        = {A framework for few-shot language model evaluation},
  month        = sep,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {v0.0.1},
  doi          = {10.5281/zenodo.5371628},
  url          = {https://doi.org/10.5281/zenodo.5371628}
}
@article{AI2,
  title={Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},
  author={Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Schoenick, Carissa and Tafjord, Oyvind}
}

@article{HellaSwag,
  title={HellaSwag: Can a Machine Really Finish Your Sentence?},
  author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin}
}
@article{MMLU,
  title={Measuring Massive Multitask Language Understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv e-prints},
  pages={arXiv--2009},
  year={2020}
}
@article{Truthful,
  title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain}
}
@misc{arena,
      title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric. P Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{fauno,
      title={Fauno: The Italian Large Language Model that will leave you senza parole!}, 
      author={Andrea Bacciu and Giovanni Trappolini and Andrea Santilli and Emanuele Rodolà and Fabrizio Silvestri},
      year={2023},
      eprint={2306.14457},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}
@inproceedings{meteor,
    title = "{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments",
    author = "Banerjee, Satanjeev  and
      Lavie, Alon",
    booktitle = "Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W05-0909",
    pages = "65--72",
}
@inproceedings{rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}
@misc{spanish-speakers,
    title = {List of languages by total number of speakers},
    author = {Wikipedia},
    howpublished = {https://en.wikipedia.org/wiki/List\_of\_languages\_by\_total\_number\_of\_speakers}

}

@misc{deepl,
    title = {DeepL},
    author = {DeepL},
    howpublished = {https://www.deepl.com/en/translator}

}
@misc{wasserstein,
    title = {Wasserstein Distance},
    author = {Wikipedia},
    howpublished = {https://en.wikipedia.org/wiki/Wasserstein\_metric}

}
@misc{fleiss,
    title = {Fleiss' kappa},
    author = {Wikipedia},
    howpublished = {https://en.wikipedia.org/wiki/Fleiss%27\_kappa}

}
@misc{chatgpt-parameters,
    title = {GPT-3},
    author = {Wikipedia},
    howpublished = {https://en.wikipedia.org/wiki/GPT-3}

}
@misc{pearson,
    title = {Pearson Correlation Coefficient},
    author = {Wikipedia},
    howpublished = {https://en.wikipedia.org/wiki/Pearson\_correlation\_coefficient}

}
@article{wei2023chainofthought,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}
@article{impersonation,
  title={In-Context Impersonation Reveals Large Language Models’ Strengths and Biases},
  author={Salewski, Leonard and Alaniz, Stephan and Rio-Torto, Isabel and Schulz, Eric and Akata, Zeynep}
}
@misc{wizard-vicuna,
      title={Wizard Vicuna LM}, 
    howpublished = {https://github.com/melodysdreamj/WizardVicunaLM}
}
@misc{mpt7b,
      title={Introducing MPT-7B: A New Standard for Open-Source, Commercially Usable LLMs}, 
    author = {MosaicML},
    howpublished = {https://www.mosaicml.com/blog/mpt-7b}
}

@misc{mpt30b,
      title={MPT-30B: Raising the bar for open-source foundation models}, 
    author = {MosaicML},
    howpublished = {https://www.mosaicml.com/blog/mpt-30b}
}
@article{falcon40b,
  title={{Falcon-40B}: an open large language model with state-of-the-art performance},
  author={Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme},
  year={2023}
}
@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@BOOK{Kim2015-es,
  title     = "Understanding narrative inquiry",
  author    = "Kim, Jeong-Hee",
  publisher = "SAGE Publications",
  month     =  may,
  year      =  2015,
  address   = "Thousand Oaks, CA"
}
@ARTICLE{Bailey2002-fw,
  title     = "Storytelling and the interpretation of meaning in qualitative
               research",
  author    = "Bailey, Patricia Hill and Tilley, Stephen",
  abstract  = "AIM: This paper reviews literature on narrative analysis and
               illustrates the meaning-making function of stories of chronic
               illness through analysis and discussion of two case studies from
               a study of acute episodes of chronic obstructive pulmonary
               disease (COPD). BACKGROUND: Individuals living with COPD
               experience acute exacerbations characterized by extreme dyspnea,
               but there has been little research to provide understanding of
               these events from the perspectives of individuals with COPD,
               family caregivers, and nurses. Narrative analysis -- considered
               in the context of the aims of qualitative research --
               illuminates how these people make sense of acute exacerbation
               events by telling stories. DESIGN AND METHODS: In an
               ethnographic study, 10 patient-family nurse units in two
               Canadian general hospitals participated in interviews concerning
               acute episodes of COPD. Narrative analysis enabled
               identification of several story forms and their functions.
               RESULTS: Examples were found of a story told twice with
               different meanings, and of a patient's 'death story' used to
               communicate distrust of the nurse's ability to recognize the
               seriousness of distress and implications for its potential
               course. These examples are presented, and interpreted with
               respect to issues of meaning. CONCLUSIONS: The analysis
               indicates that stories told by patients in the context of
               nurse-client interactions inform understanding of the
               individual's acute exacerbation events beyond the biophysical.",
  journal   = "J. Adv. Nurs.",
  publisher = "Wiley",
  volume    =  38,
  number    =  6,
  pages     = "574--583",
  month     =  jun,
  year      =  2002,
  language  = "en"
}


@article{doi:10.1080/1361332032000044567,
author = {Lee Anne Bell},
title = {Telling Tales: What stories can teach us about racism},
journal = {Race Ethnicity and Education},
volume = {6},
number = {1},
pages = {3-28},
year = {2003},
publisher = {Routledge},
doi = {10.1080/1361332032000044567},


URL = { 
    
        https://doi.org/10.1080/1361332032000044567
    
    

},
eprint = { 
    
        https://doi.org/10.1080/1361332032000044567
    
    

}

}
@BOOK{noauthor_undated-sy,
  title     = "The healing heart for families: storytelling to encourage caring
               and healthy families",
  publisher = "New Society Publishers",
  address   = "Washington"
}
@article{schramowski2022large,
  title={Large pre-trained language models contain human-like biases of what is right and wrong to do},
  author={Schramowski, Patrick and Turan, Cigdem and Andersen, Nico and Rothkopf, Constantin A and Kersting, Kristian},
  journal={Nature Machine Intelligence},
  volume={4},
  number={3},
  pages={258--268},
  year={2022},
  publisher={Nature Publishing Group UK London}
}
@article{brown2020language,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}
@Article{coadapt,
author="Danieli, Morena
and Ciulli, Tommaso
and Mousavi, Seyed Mahed
and Silvestri, Giorgia
and Barbato, Simone
and Di Natale, Lorenzo
and Riccardi, Giuseppe",
title="Assessing the Impact of Conversational Artificial Intelligence in the Treatment of Stress and Anxiety in Aging Adults: Randomized Controlled Trial",
journal="JMIR Ment Health",
year="2022",
month="Sep",
day="23",
volume="9",
number="9",
pages="e38067",
keywords="mental health care; conversational artificial intelligence; mobile health; mHealth; personal health care agent",
abstract="Background: While mental health applications are increasingly becoming available for large populations of users, there is a lack of controlled trials on the impacts of such applications. Artificial intelligence (AI)-empowered agents have been evaluated when assisting adults with cognitive impairments; however, few applications are available for aging adults who are still actively working. These adults often have high stress levels related to changes in their work places, and related symptoms eventually affect their quality of life. Objective: We aimed to evaluate the contribution of TEO (Therapy Empowerment Opportunity), a mobile personal health care agent with conversational AI. TEO promotes mental health and well-being by engaging patients in conversations to recollect the details of events that increased their anxiety and by providing therapeutic exercises and suggestions. Methods: The study was based on a protocolized intervention for stress and anxiety management. Participants with stress symptoms and mild-to-moderate anxiety received an 8-week cognitive behavioral therapy (CBT) intervention delivered remotely. A group of participants also interacted with the agent TEO. The participants were active workers aged over 55 years. The experimental groups were as follows: group 1, traditional therapy; group 2, traditional therapy and mobile health (mHealth) agent; group 3, mHealth agent; and group 4, no treatment (assigned to a waiting list). Symptoms related to stress (anxiety, physical disease, and depression) were assessed prior to treatment (T1), at the end (T2), and 3 months after treatment (T3), using standardized psychological questionnaires. Moreover, the Patient Health Questionnaire-8 and General Anxiety Disorders-7 scales were administered before the intervention (T1), at mid-term (T2), at the end of the intervention (T3), and after 3 months (T4). At the end of the intervention, participants in groups 1, 2, and 3 filled in a satisfaction questionnaire. Results: Despite randomization, statistically significant differences between groups were present at T1. Group 4 showed lower levels of anxiety and depression compared with group 1, and lower levels of stress compared with group 2. Comparisons between groups at T2 and T3 did not show significant differences in outcomes. Analyses conducted within groups showed significant differences between times in group 2, with greater improvements in the levels of stress and scores related to overall well-being. A general worsening trend between T2 and T3 was detected in all groups, with a significant increase in stress levels in group 2. Group 2 reported higher levels of perceived usefulness and satisfaction. Conclusions: No statistically significant differences could be observed between participants who used the mHealth app alone or within the traditional CBT setting. However, the results indicated significant differences within the groups that received treatment and a stable tendency toward improvement, which was limited to individual perceptions of stress-related symptoms. Trial Registration: ClinicalTrials.gov NCT04809090; https://clinicaltrials.gov/ct2/show/NCT04809090 ",
issn="2368-7959",
doi="10.2196/38067",
url="https://mental.jmir.org/2022/9/e38067",
url="https://doi.org/10.2196/38067",
url="http://www.ncbi.nlm.nih.gov/pubmed/36149730"
}
@article{huang2022towards,
  title={Towards Reasoning in Large Language Models: A Survey},
  author={Huang, Jie and Chen-Chuan Chang, Kevin},
  journal={arXiv e-prints},
  pages={arXiv--2212},
  year={2022}
}
@misc{zhao2023survey,
      title={A Survey of Large Language Models}, 
      author={Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
      year={2023},
      eprint={2303.18223},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}