\chapter{Literature review}
\label{cha:literature_review}
This section consists of a brief literature review of the concepts of personal narrative, narrative interview, large language models, and prompting. 

% \section{

% This section consists of a literature review, with a focus on three main topics Narrative Elicitation, Crowdsourcing and Large Language Models.
\section{Personal Narrative}
A personal narrative is \cite{}
\section{Narrative Interview}
Interviewing narrative is used to
\section{Large Language Models}
In recent times, there have been notable developments in the field of natural language processing through the introduction of pre-trained language models \cite{radford2018improving}. These models involve the pre-training of transformer-based architectures \cite{vaswani2017attention} on extensive text corpora and have demonstrated remarkable capabilities across various NLP tasks. As researchers delved into the potential for performance enhancement by scaling upwards the size of their models, they found interesting results. As the scale of these models exceeded certain thresholds, they not only exhibited significant performance improvements but also showcased unique abilities not observed in smaller language models. To distinguish these models based on their parameter size, the research community began referring to them as large language models among the pre-trained language models of substantial proportions. \cite{zhao2023survey,huang2022towards,wei2022emergent}

The exploration of LLMs has seen substantial advancements driven by both academic and industrial research efforts. One noteworthy milestone in this progress is the introduction of ChatGPT \cite{chatgpt}, which has garnered widespread attention and interest from society at large, due to its capabilities and ease of use. LLMs in general are found to perform well for a large variety of tasks, exhibiting human-like performances and by some are even considered to be the next step in the evolution of artificial intelligence \cite{bubeck2023sparks}.  

However, they also face a few issues. Notably one is the problem hallucinations. Hallucinations in large language models refer to instances where the model generates text or responses that are not grounded in factual information or are not based on the input provided. These hallucinations can manifest as the model generating fictional or inaccurate information that appears to be true, coherent, or contextually relevant. The model is often very confident in the correctness of its own responses, making hallucinations difficult to detect, and posing a challenge to the responsible use of these models \cite{alkaissi2023artificial,azamfirei2023large}. Hallucinations are a known challenge in the development and deployment of large language models. They can arise due to the model's capacity to generate creative and contextually coherent text based on patterns learned from the training data, even if those patterns do not reflect reality or are not appropriate for the given context. Addressing and mitigating hallucinations is an ongoing area of research and development \cite{gunjal2023detecting,mundler2023self,peng2023check}. Another importante issue concerns their large size. The sheer number of parameters present can me a significant barrier to their use, increasing the cost of access and use, as only high end expensive GPUs can run many models. For example, ChatGPT 3.5 has 175B parameters \cite{chatgpt-parameters}, and a rough math of storing the parameters as 16 bits precision estimates the requirement of running ChatGPT 3.5 to 350GB of GPU memory. Although there are many developments in crafting performing models with smaller memory requirement, they do have some tradeoffs. Many smaller models come in sizes of just 7B or 13B parameters, and are able to run on a single GPU with 16GB or 25GB of memory. However, they do not perform as well as the larger models, and are not as capable \cite{touvronllama,falcon40b,mpt7b,wizard-vicuna}. 

\section{Prompt engineering}

Prompt engineering refers to the practice of designing and formulating effective input prompts or instructions to elicit desired responses from the model. In the case of large language models, these responses are text based, but for text to image generation models the responses are images. It involves crafting input text in such a way that the model produces outputs that align with the user's intent and the task at hand. Prompt engineering is essential for improving the usability and reliability of large language models, especially when they are used in various applications, such as text generation, question answering, or language translation. \cite{white2023prompt,zhou2022learning,oppenlaender2022prompt,reynolds2021prompt}

A few key aspects that prompts for large language models should include are:
\begin{itemize}
    \item Clarity and specificity: Prompts should be clear, concise, and specific in conveying the user's request or the task's requirements \cite{}.
    \item Context setting: Providing context in the prompt can help the model condition the desired context or background information for generating relevant responses. This is particularly important for maintaining coherence in longer text generation tasks \cite{}.
    \item Formatting and structure: The structure and formatting of the prompt can influence the model's behavior. For instance, using a question format ("What is...?") can guide the model to provide informative answers, while providing a fill-in-the-blank format can lead to completing a sentence or phrase \cite{gao2023prompt}.
    \item Examples and demonstrations: Including examples or demonstrations in the prompt can help the model better condition the desired task. These can serve as reference points for the model to generate responses that match the desired style or content \cite{brown2020language, gao2023prompt}.
    \item Chain of Though and Think Step by Step: Instructing the model to generate responses in a step-by-step manner can help it generating more relevant content \cite{wei2023chainofthought}.
    \item Role giving: Giving a defined role to the model can help it better understand the task and generate more relevant responses. Providing an appropriate role can help the model generate responses that are more relevant to the domain \cite{prompt-learn}.
\end{itemize}

There are also a few ethical consideration, when designing prompts, it's important to consider ethical guidelines and avoid prompts that may lead to harmful, biased, or inappropriate outputs. Care should be taken to ensure responsible and safe use of language models \cite{li2023ethics,kasneci2023chatgpt}.

Prompts may also be used to cheat the model into generating outputs that are not grounded in reality or are not appropriate for the given context. This is known as "prompt hacking" and can be used to generate offensive or inappropriate content. Prompt hacking is a known challenge in the development and deployment of large language models. It can arise due to the model's capacity to generate creative and contextually coherent text based on patterns learned from the training data, even if those patterns do not reflect reality or are not appropriate for the given context. Addressing and mitigating prompt hacking is an ongoing area of research and development \cite{greshake2023more,secretsydney,ignore-all-previous-instructions}.