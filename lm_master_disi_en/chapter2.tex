\chapter{Literature review}
\label{cha:literature_review}
This section consists of a brief literature review of the concepts of personal narrative, narrative interview, large language models, and prompting. 

% \section{

% This section consists of a literature review, with a focus on three main topics Narrative Elicitation, Crowdsourcing and Large Language Models.
\section{Personal Narrative}
A personal narrative is defined as a story or account of events, experiences, or information told from the narrator's perspective. It is a form of storytelling that conveys a series of events, experiences, or information coherently and meaningfully. Personal narratives serve as a means of communication and are used to tell stories, share information, express ideas, or entertain. They can be used to convey personal experiences, beliefs, values, and perspectives. Personal narratives are often used in fields such as psychology, sociology, anthropology, and qualitative research to gather in-depth qualitative data and gain insights into individuals' perspectives, beliefs, and lived experiences \cite{Nurser2018-id,Charon2009-na}. They can help researchers understand how people construct and interpret their personal narratives and the meanings they attribute to various events and experiences. For instance, personal narratives may be employed in psychology to improve communication and aid problem-solving \cite{Kim2015-es}.


\section{Narrative Interview}
A narrative interview is a qualitative research method to gather in-depth information about an individual's experiences, stories, and life events. It is a form of semi-structured or open-ended interview in which the interviewer encourages the interviewee to share their life narratives, anecdotes, and stories. A narrative interview aims to capture rich and detailed accounts of the interviewee's experiences, emotions, perspectives, and the context of these events by asking interviewees questions designed to have the participant respond in a narrative \cite{Jovchelovitch2000-xs}.

There are a few caveats in the narrative interview, as it requires the interviewee to be able to recall and recount their experiences coherently and meaningfully. This process can be challenging for some individuals, especially if they have difficulty recalling events. It can also be difficult for interviewers to elicit continuations of narratives from interviewees who feel uncomfortable sharing personal information or having difficulty expressing themselves verbally. \cite{Sammantha2021-na}

The interviewer also requires some skill in eliciting continuations of narratives from the interviewee. They must be able to ask questions that encourage the interviewee to share their experiences and stories coherently and meaningfully. They must also be able to listen attentively and ask follow-up questions to clarify or expand on the interviewee's responses. They must also convey active interest in the narration or events mentioned in the narrative, providing empathy and understanding. \cite{Fairbairn2002-xd}
% It is a useful technique for gathering qualitative data and gaining insights into individuals' perspectives, beliefs, and lived experiences. It can help researchers understand how people construct and interpret their personal narratives and the meanings they attribute to various events and experiences. Narrative interviews are often used in fields such as psychology, sociology, anthropology, and qualitative research. For instance, in psychology, narrative interviews may be employed to improve communication and aid problem-solving. \cite{schutz2021narrative,riessman2008narrative,holstein2008handbook}
\section{Large Language Models}
In recent times, there have been notable developments in the field of natural language processing through the introduction of pre-trained language models \cite{radford2018improving}. These models involve pre-training transformer-based architectures \cite{vaswani2017attention} on extensive text corpora and have demonstrated remarkable capabilities across various NLP tasks. As researchers delved into the potential for performance enhancement by scaling upwards the size of their models, they found interesting results. As the scale of these models exceeded certain thresholds, they exhibited significant performance improvements and showcased unique abilities not observed in smaller language models. The research community referred to these models as large language models among the pre-trained language models of substantial proportions to distinguish these models based on their parameter size. \cite{zhao2023survey,wei2022emergent}

The exploration of LLMs has seen substantial advancements driven by both academic and industrial research efforts. One noteworthy milestone in this progress is the introduction of ChatGPT \cite{chatgpt}, which has garnered widespread attention and interest from society due to its capabilities and ease of use. LLMs in general, are found to perform well for a large variety of tasks, exhibiting human-like performances and by some are even considered to be the next step in the evolution of artificial intelligence \cite{bubeck2023sparks}.  

However, they also face a few issues. Notably, one is the problem called hallucinations. Hallucinations in large language models refer to instances where the model generates text or responses that are not grounded in factual information or are not based on the input provided. These hallucinations can manifest as the model generating fictional or inaccurate information that appears true, coherent, or contextually relevant, but in reality, it is incorrect. The models are often very confident in the correctness of their responses, making hallucinations difficult to detect, posing a challenge to the responsible use of these models \cite{alkaissi2023artificial,azamfirei2023large}. Hallucinations are a known challenge in developing and deploying large language models. They can arise due to the capacity of the model to generate creative and contextually coherent text based on patterns learned from the training data, even if those patterns do not reflect reality or are not appropriate for the given context. Addressing and mitigating hallucinations is an ongoing area of research and development \cite{gunjal2023detecting,mundler2023self,peng2023check}. Another important issue concerns their large size. The sheer number of parameters present can seen as a significant barrier to their use, increasing the cost of access and use, as only high-end expensive GPUs can run many of the available models. For example, ChatGPT 3.5 has 175B parameters \cite{chatgpt-parameters}, and a rough math of storing the parameters as 16 bits precision estimates the requirement of running ChatGPT 3.5 to 350GB of GPU memory. Although there are many developments in crafting performing models with smaller memory requirements, they have some tradeoffs. Many smaller models come in sizes of just 7B or 13B parameters and are able to run on a single GPU with 16GB or 25GB of memory. However, they do not perform as well as the larger models and are not as capable \cite{touvronllama,falcon40b,mpt7b,wizard-vicuna}. 

\section{Prompt engineering}

Prompt engineering refers to designing and formulating effective input prompts or instructions to elicit desired responses from the model. In the case of large language models, these responses are text-based, but for text-to-image generation models, their responses are images. It involves crafting input text so that the model produces outputs that align with the user's intent and the required task. Prompt engineering is essential for improving the models' large language usability and reliability, especially when used in various applications, such as text generation, question answering, or language translation \cite{white2023prompt,zhou2022learning,oppenlaender2022prompt,reynolds2021prompt,zhou-etal-2022-prompt}. 

One of the most important key aspects in designing prompts is the number of shots or examples that are given to the model. Usually, it is generally accepted that more examples help the model perform better \cite{brown2020language,reynolds2021prompt,prompt-learn,promt-eng}, although some recent findings suggest that LLMs can perform well with 0 examples as well \cite{NEURIPS2022_8bb0d291}. Other key aspects that prompts for large language models should include are: clarity and specificity, context setting, formatting and structure. Interestingly, chain-of-thought and think-step-by-step are two techniques that are found to improve the performances of the model in logical reasoning tasks by asking the model to perform the task in a step-by-step procedure \cite{wei2023chainofthought,hsieh2023distilling}.
Role-giving is also found to be an important aspect in prompting, as it helps the model better understand the task and generate more relevant responses. Providing an appropriate role can help the model generate responses that are more relevant to the domain \cite{prompt-learn}.

% A few key aspects that prompts for large language models should include are:
% \begin{itemize}
%     \item Clarity and specificity: Prompts should be clear, concise, and specific in conveying the user's request or the requirements of the task \cite{}.
%     \item Context setting: Providing context in the prompt can help the model condition the desired context or background information for generating relevant responses. This is particularly important for maintaining coherence in longer text generation tasks \cite{}.
%     \item Formatting and structure: The structure and formatting of the prompt can influence the behavior of the model. For instance, using a question format ("What is...?") can guide the model to provide informative answers, while providing a fill-in-the-blank format can lead to completing a sentence or phrase \cite{gao2023prompt}.
%     \item Examples and demonstrations: Including examples or demonstrations in the prompt can help the model better condition the desired task. These can serve as reference points for the model to generate responses that match the desired style or content \cite{brown2020language, gao2023prompt}.
%     \item Chain of Thought and Think Step by Step: Instructing the model to generate responses in a step-by-step manner can help it generating more relevant content \cite{wei2023chainofthought}.
%     \item Role giving: Giving a defined role to the model can help it better understand the task and generate more relevant responses. Providing an appropriate role can help the model generate responses that are more relevant to the domain \cite{prompt-learn}.
% \end{itemize}

There are also a few ethical considerations when designing prompts; it is important to consider ethical guidelines and avoid prompts that may lead to harmful, biased, or inappropriate outputs. Care should be taken to ensure responsible and safe use of language models \cite{li2023ethics,kasneci2023chatgpt}. Prompts may also be used to cheat the model into generating outputs that are not grounded in reality or are not appropriate for the given context. This is known as "prompt hacking" and can be used to generate offensive or inappropriate content. Prompt hacking is a known challenge in developing and deploying large language models. It can arise due to the capacity of the model to generate creative and contextually coherent text based on patterns learned from the training data, even if those patterns do not reflect reality or are not appropriate for the given context. Addressing and mitigating prompt hacking is an ongoing area of research and development \cite{greshake2023more,secretsydney,ignore-all-previous-instructions}.