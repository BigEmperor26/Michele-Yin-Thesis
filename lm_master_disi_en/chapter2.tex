\chapter{Literature review}
\label{cha:literature_review}
This section consists of a brief literature review of the concepts of personal narrative, narrative interview, large language models, and prompting. 

% \section{

% This section consists of a literature review, with a focus on three main topics Narrative Elicitation, Crowdsourcing and Large Language Models.
\section{Personal Narrative}
A personal narrative is defined as a story or account of events, experiences, or information that is told from the perspective of the narrator. It is a form of storytelling that conveys a series of events, experiences, or information coherently and meaningfully. Personal narratives serve as a means of communication and are used to tell stories, share information, express ideas, or entertain. They can be used to convey personal experiences, beliefs, values, and perspectives. Personal narratives are often used in fields such as psychology, sociology, anthropology, and qualitative research to gather in-depth qualitative data and gain insights into individuals' perspectives, beliefs, and lived experiences. They can help researchers understand how people construct and interpret their personal narratives and the meanings they attribute to various events and experiences. For instance, in psychology, personal narratives may be employed to improve communication and aid problem-solving. \cite{personal-narrative-wikipedia,personal-narrative-academic}


\section{Narrative Interview}
A narrative interview is a qualitative research method to gather in-depth information about an individual's experiences, stories, and life events. It is a form of semi-structured or open-ended interview in which the interviewer encourages the interviewee to share their life narratives, anecdotes, and stories. A narrative interview aims to capture rich and detailed accounts of the interviewee's experiences, emotions, perspectives, and the context in which these events occurred by asking interviewees questions designed to have the participant respond in a narrative \cite{Jovchelovitch2000-xs}.

There are a few caveats in narrative interview, as it requires the interviewee to be able to recall and recount their experiences in a coherent and meaningful manner. This can be challenging for some individuals, especially if they have difficulty recalling events or expressing themselves verbally. It can also be difficult for interviewers to elicit narratives from interviewees who are not comfortable sharing personal information or who have difficulty expressing themselves verbally. \cite{Sammantha2021-na}

The interviewer also requires some skill in eliciting narratives from the interviewee. They must be able to ask questions that encourage the interviewee to share their experiences and stories in a coherent and meaningful manner. They must also be able to listen attentively and ask follow-up questions to clarify or expand on the interviewee's responses. It is also required that they convey active interest in the narration or events mentioned in the narrative, providing empathy and understanding. \cite{Fairbairn2002-xd}
% It is a useful technique for gathering qualitative data and gaining insights into individuals' perspectives, beliefs, and lived experiences. It can help researchers understand how people construct and interpret their personal narratives and the meanings they attribute to various events and experiences. Narrative interviews are often used in fields such as psychology, sociology, anthropology, and qualitative research. For instance, in psychology, narrative interviews may be employed to improve communication and aid problem-solving. \cite{schutz2021narrative,riessman2008narrative,holstein2008handbook}
\section{Large Language Models}
In recent times, there have been notable developments in the field of natural language processing through the introduction of pre-trained language models \cite{radford2018improving}. These models involve the pre-training of transformer-based architectures \cite{vaswani2017attention} on extensive text corpora and have demonstrated remarkable capabilities across various NLP tasks. As researchers delved into the potential for performance enhancement by scaling upwards the size of their models, they found interesting results. As the scale of these models exceeded certain thresholds, they not only exhibited significant performance improvements but also showcased unique abilities not observed in smaller language models. To distinguish these models based on their parameter size, the research community began referring to them as large language models among the pre-trained language models of substantial proportions. \cite{zhao2023survey,huang2022towards,wei2022emergent}

The exploration of LLMs has seen substantial advancements driven by both academic and industrial research efforts. One noteworthy milestone in this progress is the introduction of ChatGPT \cite{chatgpt}, which has garnered widespread attention and interest from society at large, due to its capabilities and ease of use. LLMs in general are found to perform well for a large variety of tasks, exhibiting human-like performances and by some are even considered to be the next step in the evolution of artificial intelligence \cite{bubeck2023sparks}.  

However, they also face a few issues. Notably one is the problem hallucinations. Hallucinations in large language models refer to instances where the model generates text or responses that are not grounded in factual information or are not based on the input provided. These hallucinations can manifest as the model generating fictional or inaccurate information that appears to be true, coherent, or contextually relevant. The model is often very confident in the correctness of its own responses, making hallucinations difficult to detect, and posing a challenge to the responsible use of these models \cite{alkaissi2023artificial,azamfirei2023large}. Hallucinations are a known challenge in the development and deployment of large language models. They can arise due to the model's capacity to generate creative and contextually coherent text based on patterns learned from the training data, even if those patterns do not reflect reality or are not appropriate for the given context. Addressing and mitigating hallucinations is an ongoing area of research and development \cite{gunjal2023detecting,mundler2023self,peng2023check}. Another importante issue concerns their large size. The sheer number of parameters present can me a significant barrier to their use, increasing the cost of access and use, as only high end expensive GPUs can run many models. For example, ChatGPT 3.5 has 175B parameters \cite{chatgpt-parameters}, and a rough math of storing the parameters as 16 bits precision estimates the requirement of running ChatGPT 3.5 to 350GB of GPU memory. Although there are many developments in crafting performing models with smaller memory requirement, they do have some tradeoffs. Many smaller models come in sizes of just 7B or 13B parameters, and are able to run on a single GPU with 16GB or 25GB of memory. However, they do not perform as well as the larger models, and are not as capable \cite{touvronllama,falcon40b,mpt7b,wizard-vicuna}. 

\section{Prompt engineering}

Prompt engineering refers to the practice of designing and formulating effective input prompts or instructions to elicit desired responses from the model. In the case of large language models, these responses are text based, but for text to image generation models the responses are images. It involves crafting input text in such a way that the model produces outputs that align with the user's intent and the task at hand. Prompt engineering is essential for improving the usability and reliability of large language models, especially when they are used in various applications, such as text generation, question answering, or language translation. \cite{white2023prompt,zhou2022learning,oppenlaender2022prompt,reynolds2021prompt}

A few key aspects that prompts for large language models should include are:
\begin{itemize}
    \item Clarity and specificity: Prompts should be clear, concise, and specific in conveying the user's request or the requirements of the task \cite{}.
    \item Context setting: Providing context in the prompt can help the model condition the desired context or background information for generating relevant responses. This is particularly important for maintaining coherence in longer text generation tasks \cite{}.
    \item Formatting and structure: The structure and formatting of the prompt can influence the behavior of the model. For instance, using a question format ("What is...?") can guide the model to provide informative answers, while providing a fill-in-the-blank format can lead to completing a sentence or phrase \cite{gao2023prompt}.
    \item Examples and demonstrations: Including examples or demonstrations in the prompt can help the model better condition the desired task. These can serve as reference points for the model to generate responses that match the desired style or content \cite{brown2020language, gao2023prompt}.
    \item Chain of Though and Think Step by Step: Instructing the model to generate responses in a step-by-step manner can help it generating more relevant content \cite{wei2023chainofthought}.
    \item Role giving: Giving a defined role to the model can help it better understand the task and generate more relevant responses. Providing an appropriate role can help the model generate responses that are more relevant to the domain \cite{prompt-learn}.
\end{itemize}

There are also a few ethical considerations, when designing prompts, it is important to consider ethical guidelines and avoid prompts that may lead to harmful, biased, or inappropriate outputs. Care should be taken to ensure responsible and safe use of language models \cite{li2023ethics,kasneci2023chatgpt}.

Prompts may also be used to cheat the model into generating outputs that are not grounded in reality or are not appropriate for the given context. This is known as "prompt hacking" and can be used to generate offensive or inappropriate content. Prompt hacking is a known challenge in the development and deployment of large language models. It can arise due to the model's capacity to generate creative and contextually coherent text based on patterns learned from the training data, even if those patterns do not reflect reality or are not appropriate for the given context. Addressing and mitigating prompt hacking is an ongoing area of research and development \cite{greshake2023more,secretsydney,ignore-all-previous-instructions}.