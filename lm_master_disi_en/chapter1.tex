\chapter{Introduction}
\label{cha:intro}
%[INTRODUCE TOPIC] and [Background] 
Personal narratives are a form of storytelling, representing the recollections of events or connected sequences of events in which the narrator has played an active or passive role \cite{tammewarannotation}. These narratives, often intimate and reflective, find their expression in various mediums, from handwritten diaries to digital travelogues, encompassing both speech and text. The power of personal narratives lies in their ability to convey individual experiences, emotions, and perspectives, making them a rich source of insight into the human condition \cite{noauthor-undated-sy, doi:10.1080/1361332032000044567, Bailey2002-fw} in particular for the domain of mental health \cite{Nurser2018-id}. % CONNECT WITH TEO impictyl SOMEHOW
% TODO ADD NARRATION ACTS AND OTHER THINGS

The act of narration, however, is not a straightforward task. The narrator may experience issues during their narration, interrupting themselves because they may not know how to continue their narrative or they might not have a clear narrative flow in mind \cite{ong2019modeling}. Other issues involve difficulties in the narrator of sharing their stories due them being uncomfortable or due to the presence of sensitive topics in it \cite{Sammantha2021-na}. Narrative interviewing can be viewed as a way to mitigate these issues, with the interviewer inducing the continuation of the narration through questions. However, this task goes beyond merely asking questions; it requires a nuanced approach that involves empathetic listening and allowing the storyteller to shape their own account \cite{Kim2015-es}. This delicate interplay between interviewer and interviewee underscores the complexity of capturing authentic personal narratives.

In recent years, Large Language Models (LLMs)  have achieved remarkable success in a wide range of applications and domains, including natural language understanding and generation \cite{openai2023gpt4, touvronllama, brown2020language}. Their capacity to comprehend and generate human-like text \cite{schramowski2022large} has us posit whether LLMs can effectively elicit the continuation of personal narratives.

% The delicate interplay between interviewer and interviewee might be captured by LLMs. 
This thesis investigates the performance of LLMs in the novel task of \emph{Automatic Narrative Elicitation} (ANE). The aim is to investigate whether these models can be prompted to engage in interactions that lead to the correct elicitation of continuation of personal narratives, following a structure similar to the narrative interview. This means that these elicitations should be questions, focusing on topics mentioned in the narrative and conveying the feeling of active and interested listening to the narrator. 

In this task, each narrative is recounted by the narrator and the model is given the role of interviewer that generates questions that elicit the continuation of an interrupted narrative, prolonging the narration act from the point of interruption. To be effective, these questions have to to be short and focused on an event or topic presented in the narrative, conveying empathy and most importantly, conveying the feeling that the model is actively listening to the narrative, because this is a key requirement in an effective narrative interviewing \cite{Kim2015-es}.

To train and test deep learning models on this task, we crowdsourced a set of eliciting questions for each of the personal narratives in the CoAdapt corpus. This corpus contains 481 personal narratives in the Italian language from 45 subjects, who were employees with stress undertaking the Congnitive Behavioural therapy \cite{coadapt}. Despite the growing number of LLMs, only a few of them are suitable for the Italian language. To skim them, we designed an Italian language test to easily determine which models were suitable and which were not. The few models that could answer in Italian were subjected to the \emph{Story Cloze Test} \cite{mostafazadeh2016corpus} because this task requires a correct understanding of commonsense knowledge to predict the story closure correctly. This commonsense inference and reasoning ability is a proxy for the key listening requirement present in ANE. %\emph{Automatic Narrative Elicitation}. 
% . This revealed that many open-source LLMs do not correctly understand the Italian language due to the significant bias in English as the most widespread language in the world \cite{spanish-speakers}. 

Finally, we assessed the select LLMs on the ANE task.%of \emph{Automatic Narrative Elicitation}. In this we employed both automatic and human evaluations using as ground truth the collected questions. 
Although the results of automatic evaluation suggest that the models generate different questions from the crowdsourced ones, the results of human evaluation suggest that with some prompts, specific LLMs have the potential to attain performance levels on par with those of crowdworkers in the ANE task. % of \emph{Automatic Narrative Elicitation}. 
\\

The thesis is organized as follows:
\begin{itemize}
    \item Chapter 1: Introduction, which is this chapter.
    \item Chapter 2: Literature Review of the related topics.
    \item Chapter 3: Methodology. This chapter contains a description of the presented corpus, the LLMs selection and prompting procedure.
    \item Chapter 4: Evaluation. This chapter contains the evaluation of the results of LLMs, with both automatic and human evaluation metrics
    \item Chapter 5: Conclusion. This chapter provides a summary of the dissertation and proposes some possible future works.
\end{itemize}
% Similar tasks are \emph{story cloze test} \cite{mostafazadeh2016corpus} where a context of 4 sentences is used and the model is tasked to predict the final 5th sentence, but as far as our literature review, there are no specific applications for eliciting personal narratives. Although both story cloze test and eliciting personal narratives share the requirements of understanding both language and commonsense, they also have a few key distinctions. In particular:
% \begin{itemize}
%     \item  Eliciting a narrative implies the comprehension of two people in the narration, with one person as the narrator and the other as the listener. Compare this to the story cloze test there is only one story without other roles.
%     \item  Eliciting requires a correct understanding of the context to propose appropriate topics that are both relevant and natural.
%     \item Eliciting requires understanding of concepts such as empathy, as the narrative may be of a sorrowful or joyful nature and it is required to show empathy to the narrator.
%     \item Narratives may not always use correct language syntax and grammar.
%     \item Narratives may be incoherent and/or not follow a clear order of events. It is up to the listener to piece together these inconsistencies and come to an understanding of the topic to elicit correctly.
% \end{itemize}

% Our human evaluation shows that at least for some models, it is possible to reach the performance of crowdworkers for the task of personal narrative elicitation.
% [GOALS]

% % The advent of LLMs has changed things at an unprecedented rate. Many LLMs have been proposed, for instance, some of the most famous are ChatGPT \cite{chatgpt}, LLama \cite{touvron2023llama}, LLama2 \cite{touvron2023llama} and Bard \cite{bard}.
% % They are now currently being used for a variety of tasks ranging from simple coding suggestions, such as in Copilot \cite{copilot} \cite{chen2021evaluating} to LLM Powered Autonomous Agents \cite{llm-autonomous-agents}, and many others. Their widespread use is due to a combination of their performance and ease of use, thanks to the fact that many models have online tools to access them. Now, many models have also capabilities beyond simply text, thanks to extensions and other integrations with a plethora of other services, for instance, Microsoft AI has announced an integrated AI suite \cite{ai-plugins} and OpenAI just announced vision and audio capabilities for their GPT-4 model \cite{chatgpt-see}. Many of these LLMs have impressive results in a large variety of fields and tasks, for instance, GPT-4 can perform well in a variety of different tasks \cite{bubeck2023sparks}.

% %[research problem]
% Due to their abilities to perform well in various fields, we pose the query of whether Large Language Models (LLMs) can be used to elicit personal narratives.
% personal narratives are defined as spoken or written - recollections of facts, events, and thoughts \cite{tammewar2020annotation} and  eliciting it is ...\cite{} and it is used to \cite{} because it has many benefits. 

% %[Similar research] 
% Similar tasks are \emph{story cloze test} \cite{mostafazadeh2016corpus} where a context of 4 sentences is used and the model is tasked to predict the final 5th sentence, but as far as we know, there are no specific applications for eliciting personal narratives. 

% %[Problems] 
% Although both story cloze test and eliciting personal narratives share the requirement of understanding of commonsense, they also have a few key distinctions due to the inherent differences in the prose compared to story cloze test. In particular:
% \begin{itemize}
%     \item  Eliciting a narrative implies the comprehension of two people in the narration, with one person as the narrator and the other as the listener. Compare this to the story cloze test there is only one story without other roles.
%     \item  Eliciting requires a correct understanding of the context to propose appropriate topics that are both relevant and natural.
%     \item Eliciting requires understanding of concepts such as empathy, as the narrative may be of a sorrowful or joyful nature and it is required to show empathy to the narrator.
%     \item Narratives may not always use correct language syntax and grammar.
%     \item Narratives may be incoherent and/or not follow a clear order of events. It is up to the listener to piece together these inconsistencies and come to an understanding of the topic to elicit correctly.
% \end{itemize}
% % [GOALS]
% Our main goal is to prompt Large Language Models to elicit personal narratives and evaluate their performances compared to crowdworkers. This evaluation is done through both automatic metrics, such as BLEU, METEOR and other relevant statistics, and human evaluation according to Mahed et al \cite{}. 

% % [MAP]
% In this thesis is presented a collection of the following steps that were necessary to reach our goal:
% \begin{itemize}
%     \item New dataset collection. Since there is no existing task of personal narrative elicitation we need to define this task with a new dataset.
%     \item Crowdsourcing. As our reference points, we gathered eliciting questions for the new dataset through crowdsourcing.
%     \item LLMs prompting. A selection of LLMs was prompted for the task of eliciting personal narratives. 
%     \item Evaluation. Both automatic and human metrics are used to evaluate the obtained results
% \end{itemize}
% %[Conclusion]
% Our human evaluation shows that at least for some models, it is possible to reach the performance of crowdworkers for the task of personal narrative elicitation.

% The advent of Large Language Models (LLMs) has ushered in a transformative era in technology, fundamentally altering the way people interact with and utilize digital tools. These AI-powered behemoths, including ChatGPT, LLama, Bard, and their counterparts, have swiftly become ubiquitous, orchestrating a paradigm shift in diverse domains. They have seamlessly transitioned from mere language processors to versatile autonomous agents capable of performing an array of tasks previously entrusted to human operators. From crafting engaging narratives, summarizing extensive documents, generating intricate source code, refining written text and even aiding in autocorrection, these LLMs have proven their mettle with a growing arsenal of plugins that extend their capabilities beyond the realm of mere text manipulation.

% A \emph{personal narrative} is an account of an experience from the perspective of the narrator. It often uses a first-person point of view to tell a story, shares emotions and reflections, and may convey a lesson or insight. These narratives aim to engage readers by creating a vivid and meaningful portrayal of personal experiences. 
% Narrative elicitation is a research or interview technique used to collect qualitative data in the form of narratives or stories from individuals. It involves prompting participants to share their personal experiences, perspectives, and insights by recounting a specific event or describing a particular aspect of their lives. Narrative elicitation techniques are commonly used in various fields, including psychology, anthropology, sociology, and qualitative research in general. It can help researchers explore topics such as personal experiences, cultural practices, identity, and the impact of certain events on individuals or communities. Additionally, narrative elicitation can be a valuable tool in clinical settings, where therapists may use it to help patients express their thoughts and emotions.

% Since LLMs have proven their incredible abilities in various fields, this thesis embarks on a compelling exploration: 
% \\\\
% \centerline{Can LLMs elicit narratives just as effectively as crowdworkers?}
% \\\\
% In order to investigate properly this question, we structure this thesis in the following sections:
% \begin{itemize}
%     \item Literature review
%     \item \begin{itemize}
%         \item Dataset: we prepare a new dataset of personal narratives.
%         \item Crowdsourcing: eliciting questions for the personal narratives within the dataset are crowdsourced.
%         \item Large Language Models Prompting: a selection of large language models is prompted to elicit the same set of personal narratives.
%     \end{itemize}
%     \item Evaluation: both automatic metrics and human evaluation are applied to both the crowdsourced and LLMs generated eliciting questions. 
%     \item Conclusion: conclusions are drawn.
% \end{itemize}

% Our findings suggest that at least in some cases, LLMs can match the performance of a crowdworker for the task of personal narrative elicitation.

% \section{Large Language Models}

% % \emph{Language Model (LM)}:
% A Language Model (LM) is a computational tool used in the field of natural language processing (NLP) to understand and generate human language. It's like a statistical guide that learns language patterns from data. Think of the word suggestion feature on smartphones' keyboards â€“ that's a simple example of a language model.

% To make sense of words, various techniques and model architectures are used, like attention models with transformers, which have proven to be highly effective. When working with language models, the typical steps involve gathering a dataset (corpus), creating a dictionary of words, converting words to numbers (also known as vectorization), and designing a machine learning task (like predicting the next word). Through training, the model learns word meanings (embeddings) from the data. 

% Afterwards, in order to use the embeddings the model has learned, typically a simple solution is to attach neural network layers to the embeddings in order to shape the output to the required needs and then fine tune on a the task required.

% % \emph{Large Language Model (LLM)}:
% A Large Language Model (LLM) is an AI system designed to understand and generate human language, built using deep learning techniques. LLMs are trained on extensive text data to grasp language patterns, context, grammar, and meaning exactly like Language Models. . They excel in various language tasks, including text generation, translation, summarization, and sentiment analysis, within the realm of Natural Language Processing (NLP).

% LLMs consist of neural networks with many layers, allowing them to understand complex language nuances. The term "large" indicates their use of numerous parameters and data during training. Examples of prominent LLMs include OpenAI's GPT series and Google's BERT. LLMs predict the next word or token in a text sequence based on context, generating coherent responses. With training on diverse text sources, LLMs generate human-like text for communication, content creation, automation, and solving problems.

% The main difference between LMs and LLMs is their scale. The massive scale at which LLMs operate allows them to perform many more tasks and with significantly higher accuracy than LMs. However due to their mastodontic size, both of the model and the data they are trained on, they exibhit some emergent properties.

% One significant difference between LMs and LLMs is an emergent property of LLMs due to their size. Prompting.

% Prompting refers to providing an initial input or instruction to guide the generation of text or a response from the model. A prompt is a starting point or a query that sets the context for the language model to generate a coherent and relevant output.

% When you interact with a language model, such as giving a command to a virtual assistant or using a chatbot, you provide a prompt that outlines what you want the model to respond to or generate. The prompt can be a question, a statement, or any form of input that gives the model context about what is expected from it. The model then uses its trained knowledge and patterns to generate a response that is consistent with the given prompt.

% The choice of prompt is crucial in guiding the language model's output. A well-crafted prompt can help the model generate accurate and contextually appropriate responses, while an ambiguous or unclear prompt might result in less accurate or relevant outputs. Researchers and users often experiment with different prompts to achieve the desired outcomes from language models.

% This allows Large Language models to be used for various tasks without retraining, allowing much faster deployment and testing, which is a contributing factor for their now widespread usage.






