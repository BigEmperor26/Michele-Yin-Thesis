\chapter{Conclusion}
\label{cha:conclusion}
% \section{Conclusion}
In this work, we presented the \emph{Automatic Narrative Elicitation} (ANE) task, in which a model is required to generate a question that induces the continuation of a personal narrative. Key elements are that the model should convey the feeling of active listening to the topics presented in the narrative, and deliver empathetic responses when required. We also presented a novel corpus designed for this task, which included crowdsourced eliciting questions for continuations of personal narratives. We tested different LLMs on the ANE task using this corpus and we evaluated the results. This evaluation encompassed both automatic metrics and human evaluation. 

The human evaluation consisted in a comparison of LLMs generated eliciting questions against crowdsourced ones using the Human Evaluation Protocol \cite{mousavi-etal-2022-evaluation}, which included Correctness, Appropriateness, Contextualisation and Listening. The metrics of Appropriateness, Contextualisation and Listening were used as proxy for the requirement of conveying empathetic responses in the ANE task.
% This comparison determined that ChatGPT can be prompted to reach similar levels of a crowdworker in eliciting the continuations of personal narratives.

% brief recap on top
% To conclude our findings suggest that adequately prompted LLMs can reach performances similar to that of crowdworkers in the task of eliciting continuations of personal narratives. This validated by the results of application of the human evalution protocol. Those confirm that ChatGPT eliciting questions are rated very similarly to crowdsourced elicting questions for continuation of personal narratives. 
Our findings suggests that LLMs manage the grounding context provided  to generate adequate correct and contextualised questions based on the narrative topic. 
%% Empathetic shit
% that are related to topics of the narratives and at the same time, empathetic in the case of sorrowful or joyful events, which are key requirements in eliciting a continuation of a personal narrative.

We did find that the many of other smaller models tested did not reach such performances, and were lacking compared to ChatGPT 3.5 turbo. Many models had a few recurrent issues. In particular:
\begin{itemize}
    % \item Many LLMs suffer from the presence of non-text characters, such as \emph{\textbackslash n} or \emph{*}. Although these characters were automatically removed using pattern-matching techniques, this solution is not ideal. Inserting the outputs of the models into a machine learning-based pipeline that automatically detects non-textual characters and removes them would likely be a better solution.
    \item Some models recurrently produce either blank or non-valid characters as output. Reprompting might be a solution.
    % Using a machine learning pipeline to detect invalid outputs and re-prompt the model with a different random seed would extremely likely solve the issue.
    % \item We find that using non-text-based characters, such as brackets \emph{``["},\emph{``]"} does significantly inhibit the performances of the tested models, except for OpenAI models. This is likely because smaller open-source models are not trained on corpora containing special characters and, therefore, are very likely to confuse text.
    \item Other smaller LLMs issues in their abilities to understand and follow topics with commonsense reasoning. It is possible that using different prompts that specify to apply to either commonsense or perform the solution one step at a time may result in better results, in a similar way to what is possible to achieved with Chain of Thoughts \cite{wei2023chainofthought}, but that is outside the scope of this thesis. We suggest that their poor ability to understand common sense may be related to their issues with the Italian language, but the evidence is currently inconclusive.
    % Curating the training dataset and procedure  is a possible solution
    \item Some LLMs have issues understanding the Italian language. Curating the training dataset and procedure  is a possible solution.
\end{itemize}
% It is possible that all issues mentioned above could be solved or at least mitigated by fine-tuning on the corpus presented in this thesis.

Regarding the performance discrepancy of ChatGPT and other open-source models, is it likely due to two facts:
\begin{enumerate}
    \item The size differences, as ChatGPT has 175B parameters \cite{chatgpt-parameters} whereas the open-source models tested in this thesis, range from 7B to 40B parameters.
    \item The ChatGPT pipelines are not transparent, but it is very likely that their models include a built-in pipeline which includes a post-processing step in order to clean up the data.
\end{enumerate}

It should also be noticed that version of ChatGPT tested during this thesis is a paid model, which can be limiting factor on the accessibility and usage of its models.
% Other issues with ChatGPT

% We do recognise, however, one critical aspect of our investigation is the small size of the human evaluation. Due to time constraints, we could not evaluate all narratives across all models, and therefore we limited our comparison with the test set of ouir corpus, which is composed of 57 narratives. Furthermore, our human evaluation has a sample size of 3 people. 

\section{Future Works}
In future works, we plan on fine-tuning LLMs with the corpus presented in this thesis, focusing on the valence information. The goal is to obtain models that can correctly elicit continuation for personal narratives, with a deeper focus on their Italian language abilities and their ability in prompting questions related to valence negative or positive functional units of the narratives, as key emphatetic listening behaviour.
%Then, we plan to proceed with a more extensive human evaluation, exploiting crowdsourcing in order to gather more annotators.