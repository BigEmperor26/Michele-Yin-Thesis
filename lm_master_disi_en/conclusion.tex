\chapter{Conclusion and Future Works}
\label{cha:conclusion}
% \section{Conclusion}
To conclude our findings suggest that adequately prompted LLMs can reach performances similar to that of crowdworkers in the task of eliciting continuations of personal narratives. This validated by the results of application of the human evalution protocol. Those confirm that ChatGPT 3.5 turbo eliciting questions are rated very similarly to crowdsourced elicting questions for continuation of personal narratives. This finding suggests that LLMs can have enough understanding of commonsense to prompt questions that are related to topics of the narratives and at the same time, empathetic in the case of sorrowful or joyful events, which are key requirements in eliciting a continuation of a personal narrative.

We did find that the many of other smaller models tested did not reach such performances, and were lacking compared to ChatGPT 3.5 turbo. Many models had a few recurrent issues. In particular, we observed that LLMs have these problems:
\begin{itemize}
    \item Many LLMs suffer from the presence of non-text characters, such as \emph{\textbackslash n} or \emph{*}. Although these characters were automatically removed using pattern-matching techniques, this solution is not ideal. Inserting the outputs of the models into a machine learning-based pipeline that automatically detects non-textual characters and removes them would likely be a better solution.
    \item Some models recurrently produce either blank or non-valid characters as output. Using a machine learning pipeline to detect invalid outputs and re-prompt the model with a different random seed would extremely likely solve the issue.
    \item We find that using non-text-based characters, such as brackets \emph{``["},\emph{``]"} does significantly inhibit the performances of the tested models, except for OpenAI models. This is likely because smaller open-source models are not trained on corpora containing special characters and, therefore, are very likely to confuse text.
    \item LLLMs do have some significant issues in their abilities to understand and follow topics with commonsense reasoning. It is possible that using different prompts that specify to apply to either commonsense or perform the solution one step at a time may result in better results, in a similar way to what is possible to achieved with Chain of Thoughts \cite{wei2023chainofthought}, but that is outside the scope of this thesis. We suggest that their poor ability to understand common sense may be related to their issues with the Italian language, but the evidence is currently inconclusive.
    \item Some LLMs have issues understanding the Italian language. This issue could be easily fixed by fine-tuning the models with an Italian dataset. However, LLMs may still lapse into English, as shown by Fauno 13B, an Italian fine tuned LLMs.
\end{itemize}
It is possible that all issues mentioned above could be solved or at least mitigated by fine-tuning on the corpus presented in this thesis.

Regarding the performance discrepancy of ChatGPT 3.5 turbo and other open-source models, is it likely due to two facts:
\begin{enumerate}
    \item The size differences, as ChatGPT 3.5 has 175B parameters \cite{chatgpt-parameters} whereas the open-source models tested in this thesis, range from 7B to 40B parameters.
    \item It is very likely that OpenAI API access to their models has a built-in pipeline which includes a post-processing step in order to clean up the data.
\end{enumerate}

We do recognise, however, one critical aspect of our investigation is the small size of the human evaluation. Due to time constraints, we could not evaluate all narratives across all models, and therefore we limited our comparison with the test set of ouir corpus, which is composed of 57 narratives. Furthermore, our human evaluation has a sample size of 3 people. 

\section{Future Works}
In future works, we plan on fine-tuning LLMs with the corpus presented in this thesis, focusing on the valence information. The goal is to obtain models that can correctly elicit continuation for personal narratives, with a deeper focus on their Italian language abilities and their ability in prompting questions related to valence negative or positive functional units of the narratives, as key emphatetic listening behaviour. Then, we plan to proceed with a more extensive human evaluation, exploiting crowdsourcing in order to gather more annotators. 